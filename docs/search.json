[
  {
    "objectID": "workshop_cordelia.html",
    "href": "workshop_cordelia.html",
    "title": "DataSHIELD Workshop: Use case CORDELIA cohort, Friday 30th May 2025",
    "section": "",
    "text": "This is an R Markdown Notebook. When you execute code within the notebook, the results appear beneath the code.\nTry executing this chunk by clicking the Run button within the chunk or by placing your cursor inside it and pressing Ctrl+Shift+Enter."
  },
  {
    "objectID": "workshop_cordelia.html#installing-datashield",
    "href": "workshop_cordelia.html#installing-datashield",
    "title": "DataSHIELD Workshop: Use case CORDELIA cohort, Friday 30th May 2025",
    "section": "Installing DataSHIELD",
    "text": "Installing DataSHIELD\nFirstly: check whether we have the right R packages installed to run DataSHIELD: using the very helpful devtools package (which has already been installed for us by Stuart!), we’ll use the “Session info” command:\n\ninstall.packages(\"devtools\")\nlibrary(devtools)\ndevtools::session_info()\n\nWe are missing some of the necessary packages: “DSI”, “DSOpal” and “dsBaseClient”.\n\ninstall.packages('DSI')\ninstall.packages('DSOpal')\n\ninstall.packages('dsBaseClient', repos=c(getOption('repos'), 'http://cran.datashield.org'), dependencies=TRUE)\n\ninstall.packages(\"metafor\")\ndevtools::install_github(\"timcadman/ds-helper\")\n\nRemember to load them into this R session using “library()” command:\n\nlibrary(DSI)\n\nLoading required package: progress\n\n\nLoading required package: R6\n\nlibrary(DSOpal)\n\nLoading required package: opalr\n\n\nLoading required package: httr\n\nlibrary(dsBaseClient)\nlibrary(dsHelper)\nlibrary(metafor)\n\nLoading required package: Matrix\n\n\nLoading required package: metadat\n\n\nLoading required package: numDeriv\n\n\n\nLoading the 'metafor' package (version 4.8-0). For an\nintroduction to the package please type: help(metafor)\n\n\nCheck that they have now been added:\n\ndevtools::session_info()"
  },
  {
    "objectID": "workshop_cordelia.html#logging-in-and-assigning-data",
    "href": "workshop_cordelia.html#logging-in-and-assigning-data",
    "title": "DataSHIELD Workshop: Use case CORDELIA cohort, Friday 30th May 2025",
    "section": "Logging in and assigning data",
    "text": "Logging in and assigning data\nThe login script has to be customized to fit the data you are trying to connect to.\nThe “builder &lt;-” and “builder$append” functions are standard features.\nFor this demonstration we are connecting to simulated data- but if it was data of real people, it would be very important for us not to be able to see individual patients’ information.\n\nLet’s log in to the opal online portal to see what data there is available (https://opal-demo.obiba.org/#/project/CORDELIA)\nWe will use a subset of CORDELIA data set, in a data.frame with 196633 individuals of 38 harmonized variables. This dataset does contain some NA values.\nFor the ease of this workshop, we’ll imagine that the data is hosted in a single Opal repository. The below code creates a local R object with the login details for each study:\n\nbuilder &lt;- DSI::newDSLoginBuilder()\nbuilder$append(\n  server = \"cordelia\",\n  url = \"https://opal-demo.obiba.org\",\n  user = \"dsuser\",\n  password = \"P@ssw0rd\",\n  resource = \"CORDELIA.cordelia44\",\n)\nlogindata &lt;- builder$build()\n\nNow we need to connect, referring to the login information in the data frame we have just created:\n\nconns &lt;- DSI::datashield.login(logins = logindata, \n                                     assign = TRUE, \n                                     symbol = \"res\")\n\n\nLogging into the collaborating servers\n\n\n\nAssigning resource data...\n\n\nThe ‘assign’ argument can be set to either ‘TRUE’ or ‘FALSE’. If set to ‘TRUE’, all the available variables within that table will be assigned to a serverside data frame and available to access. If you only need a small subset of available variables it can be preferable to set this to ‘FALSE’ and later use the function ‘datashield.assign’ to separately assign only the variables you need. The output of this box has useful progress bars which show the progress of connecting to studies, one by one.\nWe can see the serverside object that has been created by running:\n\nds.ls()\n\n$cordelia\n$cordelia$environment.searched\n[1] \"R_GlobalEnv\"\n\n$cordelia$objects.found\n[1] \"res\"\n\n\nWe can see the type of object we have\n\nds.class(\"res\")\n\n$cordelia\n[1] \"RDSFileResourceClient\" \"FileResourceClient\"    \"ResourceClient\"       \n[4] \"R6\"                   \n\n\nHere you see one ‘resource’ rather than a dataframe in each study called ‘D’. NOTE, if data would be stored as a Table rather than a ‘resource’ (e.g. csv file) we would get directly ‘D’ as a table. You can see the example in our bookdown: https://isglobal-brge.github.io/resource_bookdown/datashield.html#demo\nNow we need to ‘resolve’ the resource. That is, import the object into R. In that case, as the resource is an R object, internally readRDS function is called, but it is not necessary to be executed. Instead we use the function as.resource.data.frame():\n\nDSI::datashield.assign.expr(conns = conns, \n                            symbol = \"D\",\n                            expr = quote(as.resource.data.frame(res)))\n\nNow, we can see that we have a data.frame in the server side:\n\nds.ls()\n\n$cordelia\n$cordelia$environment.searched\n[1] \"R_GlobalEnv\"\n\n$cordelia$objects.found\n[1] \"D\"   \"res\"\n\n\nand the data.frame has these variables\n\nds.summary(\"D\")\n\n$cordelia\n$cordelia$class\n[1] \"data.frame\"\n\n$cordelia$`number of rows`\n[1] 196633\n\n$cordelia$`number of columns`\n[1] 38\n\n$cordelia$`variables held`\n [1] \"cohorte\"         \"codigo\"          \"fec_inc\"         \"edad\"           \n [5] \"sexo\"            \"est_civ\"         \"niv_cult\"        \"act_fis\"        \n [9] \"fumador\"         \"HTA\"             \"HTA_TTO\"         \"hipercol\"       \n[13] \"col_tto\"         \"diabetes\"        \"diab_tto\"        \"insulin\"        \n[17] \"diab_ado_ins\"    \"peso\"            \"talla\"           \"cintura\"        \n[21] \"IMC\"             \"FC\"              \"PAS_1\"           \"PAS_2\"          \n[25] \"PAD_1\"           \"PAD_2\"           \"col_tot\"         \"hdl\"            \n[29] \"ldl\"             \"trig\"            \"creat\"           \"filt_glomer\"    \n[33] \"glu\"             \"exitusSeg\"       \"FechaExit_Seg\"   \"filt_glomer_CKD\"\n[37] \"HTA_tot\"         \"diabetes_tot\""
  },
  {
    "objectID": "workshop_cordelia.html#describing-data-aggregate-type-functions",
    "href": "workshop_cordelia.html#describing-data-aggregate-type-functions",
    "title": "DataSHIELD Workshop: Use case CORDELIA cohort, Friday 30th May 2025",
    "section": "Describing data (‘aggregate-type functions’)",
    "text": "Describing data (‘aggregate-type functions’)\nThere are many data exploration functions already implemented into DataSHIELD: let’s check it out at the wiki https://data2knowledge.atlassian.net/wiki/spaces/DSDEV/pages/2733244417/Version+6.2.0\nScroll down to “Data structure queries”. Let’s try out a few of these:\n\nds.dim(x=\"D\", datasources = conns)\n\n$`dimensions of D in cordelia`\n[1] 196633     38\n\n$`dimensions of D in combined studies`\n[1] 196633     38\n\nds.colnames(x=\"D\", datasources = conns)\n\n$cordelia\n [1] \"cohorte\"         \"codigo\"          \"fec_inc\"         \"edad\"           \n [5] \"sexo\"            \"est_civ\"         \"niv_cult\"        \"act_fis\"        \n [9] \"fumador\"         \"HTA\"             \"HTA_TTO\"         \"hipercol\"       \n[13] \"col_tto\"         \"diabetes\"        \"diab_tto\"        \"insulin\"        \n[17] \"diab_ado_ins\"    \"peso\"            \"talla\"           \"cintura\"        \n[21] \"IMC\"             \"FC\"              \"PAS_1\"           \"PAS_2\"          \n[25] \"PAD_1\"           \"PAD_2\"           \"col_tot\"         \"hdl\"            \n[29] \"ldl\"             \"trig\"            \"creat\"           \"filt_glomer\"    \n[33] \"glu\"             \"exitusSeg\"       \"FechaExit_Seg\"   \"filt_glomer_CKD\"\n[37] \"HTA_tot\"         \"diabetes_tot\"   \n\n\nNOTE: writting datasources = conns is not required. This is just to emphasize that if you have several connections you need to specify which one is yours. By default, it missing it looks for your local environment\n\nls()\n\n[1] \"builder\"   \"conns\"     \"logindata\"\n\n\nSo, this would also work\n\nds.dim(\"D\")\n\n$`dimensions of D in cordelia`\n[1] 196633     38\n\n$`dimensions of D in combined studies`\n[1] 196633     38\n\nds.colnames(\"D\")\n\n$cordelia\n [1] \"cohorte\"         \"codigo\"          \"fec_inc\"         \"edad\"           \n [5] \"sexo\"            \"est_civ\"         \"niv_cult\"        \"act_fis\"        \n [9] \"fumador\"         \"HTA\"             \"HTA_TTO\"         \"hipercol\"       \n[13] \"col_tto\"         \"diabetes\"        \"diab_tto\"        \"insulin\"        \n[17] \"diab_ado_ins\"    \"peso\"            \"talla\"           \"cintura\"        \n[21] \"IMC\"             \"FC\"              \"PAS_1\"           \"PAS_2\"          \n[25] \"PAD_1\"           \"PAD_2\"           \"col_tot\"         \"hdl\"            \n[29] \"ldl\"             \"trig\"            \"creat\"           \"filt_glomer\"    \n[33] \"glu\"             \"exitusSeg\"       \"FechaExit_Seg\"   \"filt_glomer_CKD\"\n[37] \"HTA_tot\"         \"diabetes_tot\"   \n\n\nWhat it is mandatory is to write the name of the data.frame with ““.\n\nWe’re going to be focus on hdl_cholesterol.\nThis is a measure of HDL Cholesterol (aka the “good cholesterol” level)\nLet’s run some summary statistic commands\n\nds.class(x='D$hdl', datasources = conns)\n\n$cordelia\n[1] \"numeric\"\n\nds.length(x='D$hdl', datasources = conns)\n\n$`length of D$hdl in cordelia`\n[1] 196633\n\n$`total length of D$hdl in all studies combined`\n[1] 196633\n\nds.mean(x='D$hdl', datasources = conns)\n\n$Mean.by.Study\n         EstimatedMean Nmissing Nvalid Ntotal\ncordelia      54.71801    49616 147017 196633\n\n$Nstudies\n[1] 1\n\n$ValidityMessage\n         ValidityMessage \ncordelia \"VALID ANALYSIS\"\n\n\nWhat is this other function to obtain the mean? Let’s use the DataSHIELD function help documentation.\n\n?ds.quantileMean\n\nNow, putting into action some of what we’ve learned about the function arguments. NOTE: ‘split’ is in case you have data from different servers and you want to see the statistic one by one.\n\nds.quantileMean(x='D$hdl', datasources = conns)\n\n Quantiles of the pooled data\n\n\n      5%      10%      25%      50%      75%      90%      95%     Mean \n34.20000 38.00000 44.00000 53.00000 63.00000 74.00000 82.00000 54.71801 \n\nds.quantileMean(x='D$hdl',type = \"split\", datasources = conns)\n\n$cordelia\n      5%      10%      25%      50%      75%      90%      95%     Mean \n34.20000 38.00000 44.00000 53.00000 63.00000 74.00000 82.00000 54.71801 \n\n\nTrying to calculate the variance of HDL Cholesterol:\n\n?ds.var\n\n\nds.var(x = \"D$hdl\", type = \"split\", datasources = conns)\n\n$Variance.by.Study\n         EstimatedVar Nmissing Nvalid Ntotal\ncordelia     214.2793    49616 147017 196633\n\n$Nstudies\n[1] 1\n\n$ValidityMessage\n         ValidityMessage \ncordelia \"VALID ANALYSIS\"\n\n\nCan we store the results calculated from a DataSHIELD analysis in a local R session?\nYes- the output of aggregate functions are always R objects, hence can be stored.\n\na&lt;-ds.var(x = \"D$hdl\", type = \"split\", datasources = conns)[[1]]\na\n\n         EstimatedVar Nmissing Nvalid Ntotal\ncordelia     214.2793    49616 147017 196633\n\nb&lt;-ds.var(x = \"D$hdl\", type = \"split\", datasources = conns)[[1]][[1,1]]\nb\n\n[1] 214.2793\n\n\nThe square brackets are because we are trying to access an element of a list- which is the R object that DataSHIELD aggregate functions output as.\nFactor variables visualize by simply writting\n\nds.table(\"D$sexo\")\n\n\n Data in all studies were valid \n\nStudy 1 :  No errors reported from this study\n\n\n$output.list\n$output.list$TABLE_rvar.by.study_row.props\n        study\nD$sexo   cordelia\n  Hombre        1\n  Mujer         1\n  NA          NaN\n\n$output.list$TABLE_rvar.by.study_col.props\n        study\nD$sexo    cordelia\n  Hombre 0.4633861\n  Mujer  0.5366139\n  NA     0.0000000\n\n$output.list$TABLE_rvar.by.study_counts\n        study\nD$sexo   cordelia\n  Hombre    91117\n  Mujer    105516\n  NA            0\n\n$output.list$TABLES.COMBINED_all.sources_proportions\nD$sexo\nHombre  Mujer     NA \n 0.463  0.537  0.000 \n\n$output.list$TABLES.COMBINED_all.sources_counts\nD$sexo\nHombre  Mujer     NA \n 91117 105516      0 \n\n\n$validity.message\n[1] \"Data in all studies were valid\"\n\n\n\n\nUsing dsHelper to retrieve statistics in a neater format.\nAs you may have noticed, some operations which are more straightforward in R can be more complicated in datashield. To help with this, the dsHelper package allows you to do some common operations in fewer lines of code. DsHelper is an entirely serverside package - it contains only clientside functions which call DataSHIELD functions serverside.\nWe have seen datashield has a range of functions to retrieve statistics, but is limited in that (i) you need to use different functions for different statistics, (ii) you can only get stats for one variable at a time. dh.GetStats returns many useful stats in a tibble, and allows you to retrieve stats for multiple variables at a time.\n\nneat_stats &lt;- dh.getStats(\n    df = \"D\",\n  vars = c(\"edad\", \"HTA\", \"hdl\", \"ldl\", \"trig\", \"creat\",\n           \"IMC\", \"talla\", \"cintura\", \"peso\", \"col_tto\", \n           \"diabetes\", \"diab_tto\", \"insuline\", \"FC\"))\n           \nneat_stats\n\nLet us see what happened:\n\ndatashield.errors()"
  },
  {
    "objectID": "workshop_cordelia.html#manipulating-data-assign-type-functions",
    "href": "workshop_cordelia.html#manipulating-data-assign-type-functions",
    "title": "DataSHIELD Workshop: Use case CORDELIA cohort, Friday 30th May 2025",
    "section": "Manipulating data (‘assign-type’ functions)",
    "text": "Manipulating data (‘assign-type’ functions)\nAssign-type functions are ones where a calculation is done on the data stored at the server (and results of that calculation are “assigned” to a serverside variable, and saved there), but is NOT transmitted back to the user.\nThe reason for this is that some calculations could be highly disclosive- and if such data were transmitted to the analyst, with not much effort at all, with an inverse function, the analyst could work out exactly what the raw data are- and thus the data’s privacy is broken!\nTo demonstrate:\n\nds.ls(datasources = conns)\n\n$cordelia\n$cordelia$environment.searched\n[1] \"R_GlobalEnv\"\n\n$cordelia$objects.found\n[1] \"D\"   \"res\"\n\nds.log(x='D$hdl', newobj='hdl_log', datasources = conns)\nds.ls(datasources = conns)\n\n$cordelia\n$cordelia$environment.searched\n[1] \"R_GlobalEnv\"\n\n$cordelia$objects.found\n[1] \"D\"       \"hdl_log\" \"res\"    \n\nds.mean(x=\"hdl_log\",datasources= conns)\n\n$Mean.by.Study\n         EstimatedMean Nmissing Nvalid Ntotal\ncordelia      3.967543    49616 147017 196633\n\n$Nstudies\n[1] 1\n\n$ValidityMessage\n         ValidityMessage \ncordelia \"VALID ANALYSIS\"\n\nds.mean(x=\"D$hdl\",datasources= conns)\n\n$Mean.by.Study\n         EstimatedMean Nmissing Nvalid Ntotal\ncordelia      54.71801    49616 147017 196633\n\n$Nstudies\n[1] 1\n\n$ValidityMessage\n         ValidityMessage \ncordelia \"VALID ANALYSIS\"\n\n\nThe second “ds.mean” shows that the mean of the logged values are definitely smaller, by about the right amount. The DataSHIELD log function has worked.\nThere is another DataSHIELD assign function that can be used for data transformations - a square root function. Let’s test again:\n\nds.sqrt(x='D$hdl', newobj='hdl_sqrt', datasources = conns)\nds.ls(datasources = conns)\n\n$cordelia\n$cordelia$environment.searched\n[1] \"R_GlobalEnv\"\n\n$cordelia$objects.found\n[1] \"D\"        \"hdl_log\"  \"hdl_sqrt\" \"res\"     \n\nds.mean(x=\"hdl_sqrt\",datasources= conns)\n\n$Mean.by.Study\n         EstimatedMean Nmissing Nvalid Ntotal\ncordelia      7.333391    49616 147017 196633\n\n$Nstudies\n[1] 1\n\n$ValidityMessage\n         ValidityMessage \ncordelia \"VALID ANALYSIS\"\n\nds.mean(x=\"D$hdl\",datasources= conns)\n\n$Mean.by.Study\n         EstimatedMean Nmissing Nvalid Ntotal\ncordelia      54.71801    49616 147017 196633\n\n$Nstudies\n[1] 1\n\n$ValidityMessage\n         ValidityMessage \ncordelia \"VALID ANALYSIS\"\n\n\nThese new objects are not attached to a dataframe. Use the help function to find out about the ds.dataFrame function, which can be used to combine objects.\nNow join “hdl_sqrt” and “hdl_log” to the dataframe “D”.\n\nds.dataFrame(c(\"D\", \"hdl_sqrt\", \"hdl_log\"), newobj = \"D\")\n\n$is.object.created\n[1] \"A data object &lt;D&gt; has been created in all specified data sources\"\n\n$validity.check\n[1] \"&lt;D&gt; appears valid in all sources\"\n\nds.colnames(\"D\")\n\n$cordelia\n [1] \"cohorte\"         \"codigo\"          \"fec_inc\"         \"edad\"           \n [5] \"sexo\"            \"est_civ\"         \"niv_cult\"        \"act_fis\"        \n [9] \"fumador\"         \"HTA\"             \"HTA_TTO\"         \"hipercol\"       \n[13] \"col_tto\"         \"diabetes\"        \"diab_tto\"        \"insulin\"        \n[17] \"diab_ado_ins\"    \"peso\"            \"talla\"           \"cintura\"        \n[21] \"IMC\"             \"FC\"              \"PAS_1\"           \"PAS_2\"          \n[25] \"PAD_1\"           \"PAD_2\"           \"col_tot\"         \"hdl\"            \n[29] \"ldl\"             \"trig\"            \"creat\"           \"filt_glomer\"    \n[33] \"glu\"             \"exitusSeg\"       \"FechaExit_Seg\"   \"filt_glomer_CKD\"\n[37] \"HTA_tot\"         \"diabetes_tot\"    \"hdl_sqrt\"        \"hdl_log\"        \n\n\nEXERCISE: Using some of the functions above, explore the distribution of the variable “PM_BMI_CATEGORICAL” in dataframe “D”.\nHere you see this has returned a list of two tibbles separated into continuous and categorical information. For the categorical variables info is returned on ns, percentages and missingness within each category, whilst for continuous variables info is returned on mean, standard deviation, quantiles and also missingness."
  },
  {
    "objectID": "workshop_cordelia.html#sub-setting-data",
    "href": "workshop_cordelia.html#sub-setting-data",
    "title": "DataSHIELD Workshop: Use case CORDELIA cohort, Friday 30th May 2025",
    "section": "Sub-setting data",
    "text": "Sub-setting data\nIn DataSHIELD there is one function that allows sub-setting of data, ds.dataFrameSubset .\nYou may wish to use it to:\nSubset a column of data by its “Class” Subset a dataframe to remove any “NA”s Subset a numeric column of a dataframe using a Boolean inequalilty\n\n# first find the column name you wish to refer to\nds.colnames(x=\"D\")\n\n$cordelia\n [1] \"cohorte\"         \"codigo\"          \"fec_inc\"         \"edad\"           \n [5] \"sexo\"            \"est_civ\"         \"niv_cult\"        \"act_fis\"        \n [9] \"fumador\"         \"HTA\"             \"HTA_TTO\"         \"hipercol\"       \n[13] \"col_tto\"         \"diabetes\"        \"diab_tto\"        \"insulin\"        \n[17] \"diab_ado_ins\"    \"peso\"            \"talla\"           \"cintura\"        \n[21] \"IMC\"             \"FC\"              \"PAS_1\"           \"PAS_2\"          \n[25] \"PAD_1\"           \"PAD_2\"           \"col_tot\"         \"hdl\"            \n[29] \"ldl\"             \"trig\"            \"creat\"           \"filt_glomer\"    \n[33] \"glu\"             \"exitusSeg\"       \"FechaExit_Seg\"   \"filt_glomer_CKD\"\n[37] \"HTA_tot\"         \"diabetes_tot\"    \"hdl_sqrt\"        \"hdl_log\"        \n\n# then check which levels you need to apply a boolean operator to:\nds.levels(x=\"D$sexo\")\n\n$cordelia\n$cordelia$Levels\n[1] \"Hombre\"     \"Mujer\"      \"No binario\"\n\n$cordelia$ValidityMessage\n[1] \"VALID ANALYSIS\"\n\n?ds.dataFrameSubset\n\nSplitting into SEX groups, assigned to different server-side objects.\n\nds.dataFrameSubset(df.name = \"D\", \n                   V1.name = \"D$sexo\", \n                   V2.name = \"Hombre\", \n                   Boolean.operator = \"==\", \n                   newobj = \"cordelia.subset.Hombres\", datasources= conns)\n\nds.dataFrameSubset(df.name = \"D\", \n                   V1.name = \"D$sexo\", \n                   V2.name = 'Mujer', \n                   Boolean.operator = \"==\", \n                   newobj = \"cordelia.subset.Mujeres\",datasources= conns)\n\nNow there are two serverside objects which have split GENDER by class, to which we have assigned the names “cordelia.subset.Hombres” and “cordelia.subset.Mujeres”.\n\nSub-setting to remove NAs\n\nds.completeCases(x1=\"D\", newobj=\"D_without_NA\", datasources=conns)\n\n$is.object.created\n[1] \"A data object &lt;D_without_NA&gt; has been created in all specified data sources\"\n\n$validity.check\n[1] \"&lt;D_without_NA&gt; appears valid in all sources\"\n\n\n\n\nSub-setting by inequality\nSay we wanted to have a subset of patients where BMI values are ≥ 25, and call it subset.BMI.25.plus\n\nds.dataFrameSubset(df.name = \"D\",\n  V1.name = \"D$IMC\",\n  V2.name = \"25\",\n  Boolean.operator = \"&gt;=\",\n  newobj = \"subset.IMC.25.plus\",\n  datasources = conns)\n\n$is.object.created\n[1] \"A data object &lt;subset.IMC.25.plus&gt; has been created in all specified data sources\"\n\n$validity.check\n[1] \"&lt;subset.IMC.25.plus&gt; appears valid in all sources\"\n\n\nChecking we have successfully created such an object, using quantiles and histograms:\n\nds.quantileMean(x=\"subset.IMC.25.plus$IMC\", \n                datasources= conns)\n\n Quantiles of the pooled data\n\n\n      5%      10%      25%      50%      75%      90%      95%     Mean \n25.39000 25.79000 26.93000 28.89000 31.63000 34.87000 37.13000 29.75356 \n\nds.histogram(x=\"subset.IMC.25.plus$IMC\", datasources = conns)\n\nWarning: cordelia: 0 invalid cells\n\n\n\n\n\n\n\n\n\n$breaks\n [1] 24.06676 26.78037 29.49398 32.20759 34.92120 37.63480 40.34841 43.06202\n [9] 45.77563 48.48924 51.20285\n\n$counts\n [1] 31834 46723 30274 15819  7660  3473  1464   619   297    91\n\n$density\n [1] 0.0848528305 0.1245391343 0.0806946846 0.0421651984 0.0204175624\n [6] 0.0092572055 0.0039022600 0.0016499310 0.0007916470 0.0002425585\n\n$mids\n [1] 25.42357 28.13718 30.85078 33.56439 36.27800 38.99161 41.70522 44.41883\n [9] 47.13243 49.84604\n\n$xname\n[1] \"xvect\"\n\n$equidist\n[1] TRUE\n\nattr(,\"class\")\n[1] \"histogram\"\n\n\n\n\nSub-setting by multiple conditions\nIf we want to create a subset based on multiple conditions we can use the ds.Boole function before subsetting. For example, let’s say that we want to create a subset of individuals where BMI values are ≥ 25 and adjusted glucose is lower than 6.\n\nds.Boole(\n  V1 = \"D$IMC\",\n  V2 = \"25\",\n  Boolean.operator = \"&gt;=\",\n  numeric.output = TRUE,\n  newobj = \"IMC.25.plus\",\n  datasources = conns)\n\n$is.object.created\n[1] \"A data object &lt;IMC.25.plus&gt; has been created in all specified data sources\"\n\n$validity.check\n[1] \"&lt;IMC.25.plus&gt; appears valid in all sources\"\n\nds.Boole(\n  V1 = \"D$glu\",\n  V2 = \"90\",\n  Boolean.operator = \"&lt;\",\n  numeric.output = TRUE,\n  newobj = \"glu.90.less\",\n  datasources = conns)\n\n$is.object.created\n[1] \"A data object &lt;glu.90.less&gt; has been created in all specified data sources\"\n\n$validity.check\n[1] \"&lt;glu.90.less&gt; appears valid in all sources\"\n\n\nWe can then use the ds.make function to make a new categorical variable which combines these groups:\n\n?ds.make \n\nds.make(toAssign = \"IMC.25.plus+glu.90.less\",\n        newobj = \"IMC.25.plus_glu.90.less\",\n        datasources = conns)\n\n$is.object.created\n[1] \"A data object &lt;IMC.25.plus_glu.90.less&gt; has been created in all specified data sources\"\n\n$validity.check\n[1] \"&lt;IMC.25.plus_glu.90.less&gt; appears valid in all sources\"\n\n# If BMI &gt;= 25 and glucose &lt; 6, then BMI.25.plus_GLUC.6.less=2\n# If BMI &gt;= 25 and glucose &gt;= 6, then BMI.25.plus_GLUC.6.less=1\n# If BMI &lt; 25 and glucose &lt; 6, then BMI.25.plus_GLUC.6.less=1\n# If BMI &lt; 25 and glucose &gt;= 6, then BMI.25.plus_GLUC.6.less=0\n\nds.table(rvar= \"IMC.25.plus_glu.90.less\",\n         datasources = conns)\n\n\n Data in all studies were valid \n\nStudy 1 :  No errors reported from this study\n\n\n$output.list\n$output.list$TABLE_rvar.by.study_row.props\n                       study\nIMC.25.plus_glu.90.less cordelia\n                     0         1\n                     1         1\n                     2         1\n                     NA        1\n\n$output.list$TABLE_rvar.by.study_col.props\n                       study\nIMC.25.plus_glu.90.less  cordelia\n                     0  0.0919276\n                     1  0.4458763\n                     2  0.1587119\n                     NA 0.3034842\n\n$output.list$TABLE_rvar.by.study_counts\n                       study\nIMC.25.plus_glu.90.less cordelia\n                     0     18076\n                     1     87674\n                     2     31208\n                     NA    59675\n\n$output.list$TABLES.COMBINED_all.sources_proportions\nIMC.25.plus_glu.90.less\n     0      1      2     NA \n0.0919 0.4460 0.1590 0.3030 \n\n$output.list$TABLES.COMBINED_all.sources_counts\nIMC.25.plus_glu.90.less\n    0     1     2    NA \n18076 87674 31208 59675 \n\n\n$validity.message\n[1] \"Data in all studies were valid\"\n\nds.dataFrame(x=c(\"D\", \"IMC.25.plus_glu.90.less\"), newobj = \"D2\")\n\n$is.object.created\n[1] \"A data object &lt;D2&gt; has been created in all specified data sources\"\n\n$validity.check\n[1] \"&lt;D2&gt; appears valid in all sources\"\n\nds.colnames(\"D2\")\n\n$cordelia\n [1] \"cohorte\"                 \"codigo\"                 \n [3] \"fec_inc\"                 \"edad\"                   \n [5] \"sexo\"                    \"est_civ\"                \n [7] \"niv_cult\"                \"act_fis\"                \n [9] \"fumador\"                 \"HTA\"                    \n[11] \"HTA_TTO\"                 \"hipercol\"               \n[13] \"col_tto\"                 \"diabetes\"               \n[15] \"diab_tto\"                \"insulin\"                \n[17] \"diab_ado_ins\"            \"peso\"                   \n[19] \"talla\"                   \"cintura\"                \n[21] \"IMC\"                     \"FC\"                     \n[23] \"PAS_1\"                   \"PAS_2\"                  \n[25] \"PAD_1\"                   \"PAD_2\"                  \n[27] \"col_tot\"                 \"hdl\"                    \n[29] \"ldl\"                     \"trig\"                   \n[31] \"creat\"                   \"filt_glomer\"            \n[33] \"glu\"                     \"exitusSeg\"              \n[35] \"FechaExit_Seg\"           \"filt_glomer_CKD\"        \n[37] \"HTA_tot\"                 \"diabetes_tot\"           \n[39] \"hdl_sqrt\"                \"hdl_log\"                \n[41] \"IMC.25.plus_glu.90.less\"\n\nds.dataFrameSubset(df.name = \"D2\",\n  V1.name = \"D2$IMC.25.plus_glu.90.less\",\n  V2.name = \"2\",\n  Boolean.operator = \"==\",\n  newobj = \"subset2\",\n  datasources = conns)\n\n$is.object.created\n[1] \"A data object &lt;subset2&gt; has been created in all specified data sources\"\n\n$validity.check\n[1] \"&lt;subset2&gt; appears valid in all sources\"\n\nds.dim(\"subset2\")\n\n$`dimensions of subset2 in cordelia`\n[1] 31208    41\n\n$`dimensions of subset2 in combined studies`\n[1] 31208    41"
  },
  {
    "objectID": "workshop_cordelia.html#data-manipulation-with-dshelper",
    "href": "workshop_cordelia.html#data-manipulation-with-dshelper",
    "title": "DataSHIELD Workshop: Use case CORDELIA cohort, Friday 30th May 2025",
    "section": "Data manipulation with dsHelper",
    "text": "Data manipulation with dsHelper\nAgain, we can use some dsHelper functions to do data manipulation operations in a more efficient way.\n\nCreate a subset of columns by a vector of column names\n\ndh.dropCols(\n    df = \"D\", \n  vars = c(\"IMC\", \"sexo\"), \n  type = \"keep\",\n  new_obj = \"df_subset\")\n\nWarning: `dh.dropCols()` was deprecated in dsHelper 1.6.0.\nℹ Please use `dsTidyverseClient::ds.select()` instead.\n\n\n$cordelia\n$cordelia$is.object.created\n[1] \"A data object &lt;df_subset&gt; has been created in all specified data sources\"\n\n$cordelia$validity.check\n[1] \"&lt;df_subset&gt; appears valid in all sources\"\n\nds.colnames(\"df_subset\")\n\n$cordelia\n[1] \"sexo\" \"IMC\" \n\n\n\n\nRename variables\n\ndh.renameVars(\n    df = \"D\", \n  current_names = c(\"IMC\", \"sexo\"),\n  new_names = c(\"bmi\", \"sex\"))\n\nWarning: `dh.renameVars()` was deprecated in dsHelper 1.6.0.\nℹ Please use `dsTidyverseClient::ds.rename()` instead.\n\n\nWarning: `dh.tidyEnv()` was deprecated in dsHelper 1.6.0.\nℹ Please use `dsBaseClient::ds.rm()` instead.\nℹ The deprecated feature was likely used in the dsHelper package.\n  Please report the issue at\n  &lt;https://github.com/lifecycle-project/ds-helper/issues/&gt;.\n\nds.colnames(\"D\")\n\n$cordelia\n [1] \"cohorte\"         \"codigo\"          \"fec_inc\"         \"edad\"           \n [5] \"est_civ\"         \"niv_cult\"        \"act_fis\"         \"fumador\"        \n [9] \"HTA\"             \"HTA_TTO\"         \"hipercol\"        \"col_tto\"        \n[13] \"diabetes\"        \"diab_tto\"        \"insulin\"         \"diab_ado_ins\"   \n[17] \"peso\"            \"talla\"           \"cintura\"         \"FC\"             \n[21] \"PAS_1\"           \"PAS_2\"           \"PAD_1\"           \"PAD_2\"          \n[25] \"col_tot\"         \"hdl\"             \"ldl\"             \"trig\"           \n[29] \"creat\"           \"filt_glomer\"     \"glu\"             \"exitusSeg\"      \n[33] \"FechaExit_Seg\"   \"filt_glomer_CKD\" \"HTA_tot\"         \"diabetes_tot\"   \n[37] \"hdl_sqrt\"        \"hdl_log\"         \"bmi\"             \"sex\"            \n\n\nThere are many more dsHelper functions designed to make common operations easier in datashield, check out the vignettes at: https://github.com/timcadman/ds-helper/blob/master/vignettes/ds-helper-main-vignette.Rmd\nEXERCISE: try some of them (Transforming continuous variable to interquartile range; use dh.getStats(), …)"
  },
  {
    "objectID": "workshop_cordelia.html#graphs",
    "href": "workshop_cordelia.html#graphs",
    "title": "DataSHIELD Workshop: Use case CORDELIA cohort, Friday 30th May 2025",
    "section": "Graphs",
    "text": "Graphs\nVisualising the data we are studying is extremely important to get a sense of it. While it may seem disclosive at first glance, only such graphs that are definitively non-disclosive have been implemented within the DataSHIELD project.\n\nHistograms\nFirstly, histograms give a good sense of how one variable is distributed. But no individual points are disclosed because values are “binned” into groups of a similar magnitude, disguising what each one actually is. We protect privacy by removing bins with low counts (below specific threshold). If you have a symmetric distribution, you may find some things aren’t observed at the extreme ends.\nLet’s create a histogram of the variable we’ve been investigating for much of this study: HDL Cholesterol (“LAB_HDL”).\n\n?ds.histogram\nds.histogram(x='D$hdl', datasources = conns)\n\nWarning: cordelia: 0 invalid cells\n\n\n\n\n\n\n\n\n\n$breaks\n [1]  19.25341  30.64614  42.03886  53.43159  64.82432  76.21704  87.60977\n [8]  99.00249 110.39522 121.78795 133.18067\n\n$counts\n [1]  2681 26654 46725 37910 21126  7854  2846   884   257    80\n\n$density\n [1] 1.600669e-03 1.591355e-02 2.789678e-02 2.263386e-02 1.261311e-02\n [6] 4.689167e-03 1.699181e-03 5.277850e-04 1.534398e-04 4.776335e-05\n\n$mids\n [1]  24.94977  36.34250  47.73523  59.12795  70.52068  81.91340  93.30613\n [8] 104.69886 116.09158 127.48431\n\n$xname\n[1] \"xvect\"\n\n$equidist\n[1] TRUE\n\nattr(,\"class\")\n[1] \"histogram\"\n\n\nUse the ds.histogram to explore the distribution of “D$hdl”\n\n\nScatterplots of two numerical variables\nWhen you generate a scatter plot, you can say that the data points that are displayed are not the actual values. The function gives you the choice on how to anonymise: either you anonymise the values by additional random noise; or you take the average of the k nearest neighbours. (for more details on how anonymisation methods are used for the generation of privacy-preserving visualisations you can have a look on the paper https://epjdatascience.springeropen.com/articles/10.1140/epjds/s13688-020-00257-4)\n\nds.scatterPlot(x=\"D$hdl\", y=\"D$bmi\", datasources = conns)\n\n\n\n\n\n\n\n\n[1] \"Split plot created\"\n\n\nOther DataSHIELD graphical functions allow the creation of box plots, heatmap plots and contour plots. Investigate them using their help functions:\n\n?ds.heatmapPlot\n?ds.contourPlot\n?ds.boxPlot"
  },
  {
    "objectID": "workshop_cordelia.html#analysis",
    "href": "workshop_cordelia.html#analysis",
    "title": "DataSHIELD Workshop: Use case CORDELIA cohort, Friday 30th May 2025",
    "section": "Analysis",
    "text": "Analysis\n\nSimple Linear Regression\nWe want to examine the relationship between BMI and HDL Cholesterol\n\nds.cor(x='D$bmi', y='D$hdl')\n\n$cordelia\n$cordelia$`Number of missing values in each variable`\n     x.val y.val\n[1,]  2796 49616\n\n$cordelia$`Number of missing values casewise`\n      x.val y.val\nx.val 51577 51577\ny.val 51577 51577\n\n$cordelia$`Correlation Matrix`\n         [,1]     [,2]\n[1,]  1.00000 -0.23775\n[2,] -0.23775  1.00000\n\n$cordelia$`Number of complete cases used`\n       x.val  y.val\nx.val 145056 145056\ny.val 145056 145056\n\n\nRegress HDL Cholesterol with BMI using the Individual Partition Data (IPD) approach:\nThe method for this (ds.glm) is a “pooled analysis”- equivalent to placing the individual-level data from all sources in one warehouse.\nImportant to note that the link function is by default the canonical link function for each family. So binomial &lt;-&gt; logistic link, poisson &lt;-&gt; log link, gaussian &lt;-&gt; identity link.\n\nmod &lt;- ds.glm(formula = \"D$hdl~D$bmi\", \n              family=\"gaussian\", datasources = conns)\n\nIteration 1...\n\n\nCURRENT DEVIANCE:      465494800.068838\n\n\nIteration 2...\n\n\nCURRENT DEVIANCE:      29334479.8256277\n\n\nIteration 3...\n\n\nCURRENT DEVIANCE:      29334479.8256277\n\n\nSUMMARY OF MODEL STATE after iteration 3\n\n\nCurrent deviance 29334479.8256277 on 145054 degrees of freedom\n\n\nConvergence criterion TRUE (1.26993568930035e-16)\n\n\n\nbeta: 75.5495097308206 -0.75141396155349\n\n\n\nInformation matrix overall:\n\n\n            (Intercept)     D$bmi\n(Intercept)      145056   4020225\nD$bmi           4020225 114533139\n\n\n\nScore vector overall:\n\n\n                     [,1]\n(Intercept) -2.414154e-09\nD$bmi       -1.133384e-07\n\n\n\nCurrent deviance: 29334479.8256277\n\nmod\n\n$Nvalid\n[1] 145056\n\n$Nmissing\n[1] 51577\n\n$Ntotal\n[1] 196633\n\n$disclosure.risk\n         RISK OF DISCLOSURE\ncordelia                  0\n\n$errorMessage\n         ERROR MESSAGES\ncordelia \"No errors\"   \n\n$nsubs\n[1] 145056\n\n$iter\n[1] 3\n\n$family\n\nFamily: gaussian \nLink function: identity \n\n\n$formula\n[1] \"D$hdl ~ D$bmi\"\n\n$coefficients\n             Estimate  Std. Error   z-value p-value  low0.95CI high0.95CI\n(Intercept) 75.549510 0.226494053 333.56068       0 75.1055895 75.9934299\nD$bmi       -0.751414 0.008060446 -93.22238       0 -0.7672121 -0.7356158\n\n$dev\n[1] 29334480\n\n$df\n[1] 145054\n\n$output.information\n[1] \"SEE TOP OF OUTPUT FOR INFORMATION ON MISSING DATA AND ERROR MESSAGES\"\n\n\nWe can use ds-helper to nicely see the output\n\ndh.lmTab(\n  model = mod, \n  type = \"glm_ipd\", \n  direction = \"wide\", \n  ci_format  = \"separate\")\n\n# A tibble: 2 × 7\n  variable    est    se pvalue lowci uppci  n_obs\n  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;int&gt;\n1 intercept 75.6   0.23      0 75.1  76.0  145056\n2 D$bmi     -0.75  0.01      0 -0.77 -0.74 145056\n\n\nWe can perfome Study-Level Meta-Analysis (SLMA) approach (not work in our case). See https://isglobal-brge.github.io/resource_bookdown/basic-statistical-analyses.html#analysis-from-a-multiple-studies\n\n\nModelling multiple variables and interactions\nAlso possible to model multiple explanatory variables and include interactions:\n\nglm_mod1&lt;-ds.glm(formula=\"D$diabetes ~ D$bmi + D$hdl*D$sex\", \n                 family='binomial', datasources = conns)\n\nIteration 1...\n\n\nCURRENT DEVIANCE:      200374.986956269\n\n\nIteration 2...\n\n\nCURRENT DEVIANCE:      102254.170101224\n\n\nIteration 3...\n\n\nCURRENT DEVIANCE:      95789.7462932103\n\n\nIteration 4...\n\n\nCURRENT DEVIANCE:      95248.3393610254\n\n\nIteration 5...\n\n\nCURRENT DEVIANCE:      95236.9068383933\n\n\nIteration 6...\n\n\nCURRENT DEVIANCE:      95236.8970482874\n\n\nIteration 7...\n\n\nCURRENT DEVIANCE:      95236.8970482786\n\n\nSUMMARY OF MODEL STATE after iteration 7\n\n\nCurrent deviance 95236.8970482786 on 144535 degrees of freedom\n\n\nConvergence criterion TRUE (9.22893105657035e-14)\n\n\n\nbeta: 3.08491640473389 -0.0825309780857893 0.024942933970396 -0.381552484080263 0.0090354208548068\n\n\n\nInformation matrix overall:\n\n\n                 (Intercept)      D$bmi      D$hdl D$sexMujer D$hdl:D$sexMujer\n(Intercept)        13675.694   401865.8   677173.2   6183.584         330412.5\nD$bmi             401865.814 12140665.2 19765808.1 184165.119        9750598.0\nD$hdl             677173.249 19765808.1 35578778.8 330412.524       18621939.2\nD$sexMujer          6183.584   184165.1   330412.5   6183.584         330412.5\nD$hdl:D$sexMujer  330412.524  9750598.0 18621939.2 330412.524       18621939.2\n\n\n\nScore vector overall:\n\n\n                         [,1]\n(Intercept)      3.678004e-09\nD$bmi            9.976590e-08\nD$hdl            2.671203e-07\nD$sexMujer       3.711755e-09\nD$hdl:D$sexMujer 2.674497e-07\n\n\n\nCurrent deviance: 95236.8970482786\n\n\nThe “*” between LAB_HDL and SEX means fit all possible main effects and interactions between the two covariates."
  },
  {
    "objectID": "workshop_cordelia.html#at-the-end-of-your-rstudio-server-analysis",
    "href": "workshop_cordelia.html#at-the-end-of-your-rstudio-server-analysis",
    "title": "DataSHIELD Workshop: Use case CORDELIA cohort, Friday 30th May 2025",
    "section": "At the end of your RStudio Server analysis:",
    "text": "At the end of your RStudio Server analysis:\nYou can save your workspace:\n\nDSI::datashield.workspace_save(conns = conns, ws = \"workspace2025\")\n\nDon’t forget to log out! Using:\n\nDSI::datashield.logout(conns)\n\nYou can restore your workspace, the next time you want to continue with your analysis\n\nconns &lt;- datashield.login(logins = logindata, \n                          assign = TRUE, symbol = \"D\")\n\n\nLogging into the collaborating servers\n\n\n\nAssigning resource data...\n\nds.ls()\n\n$cordelia\n$cordelia$environment.searched\n[1] \"R_GlobalEnv\"\n\n$cordelia$objects.found\n[1] \"D\"\n\ndatashield.logout(conns)\n\nconns &lt;- datashield.login(logins = logindata, restore = \"workspace2025\")\n\n\nLogging into the collaborating servers\n\nds.ls()\n\n$cordelia\n$cordelia$environment.searched\n[1] \"R_GlobalEnv\"\n\n$cordelia$objects.found\n [1] \"bmi\"                     \"D\"                      \n [3] \"D_without_NA\"            \"D2\"                     \n [5] \"df_subset\"               \"diabetes\"               \n [7] \"glu.90.less\"             \"hdl\"                    \n [9] \"hdl_log\"                 \"hdl_sqrt\"               \n[11] \"IMC.25.plus\"             \"IMC.25.plus_glu.90.less\"\n[13] \"ONES\"                    \"res\"                    \n[15] \"sex\"                     \"subset.IMC.25.plus\"     \n[17] \"subset2\"                \n\n\nAlso you can delete unwanted workspaces using the datashield.workspace_rm\nIn Rstudio Server: DON’T forget to use the orange “quit the current R session” button (top right of browser screen) before closing the tab- otherwise you will experience an error message the next time you try to log in."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DataSHIELD CORDELIA Workshop",
    "section": "",
    "text": "This website hosts the materials and exercises for the DataSHIELD workshop for the CORDELIA project. On it you will find reading materials, setup tutorials, workshop indications and practical exercises.\nThe workshop is organized by BRGE (Bioinformatics Research Group in Epidemiology) from the Barcelona Institute for Global Health (iSGlobal).\n\n\nAll practical exercises will be conducted using the public Opal demo server. This server provides a fully functional DataSHIELD environment with sample datasets that workshop participants can use to replicate the examples.\nLogin credentials for the demo server are:\n\nUsername: dsuser\nPassword: P@ssw0rd\n\nBefore starting, make sure to install the required R packages in your local machine:\ninstall.packages('DSI')\ninstall.packages('DSOpal')\n\ninstall.packages('dsBaseClient', repos=c(getOption('repos'), 'http://cran.datashield.org'), dependencies=TRUE)\n\ninstall.packages(\"metafor\")\ndevtools::install_github(\"timcadman/ds-helper\")"
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "DataSHIELD CORDELIA Workshop",
    "section": "",
    "text": "All practical exercises will be conducted using the public Opal demo server. This server provides a fully functional DataSHIELD environment with sample datasets that workshop participants can use to replicate the examples.\nLogin credentials for the demo server are:\n\nUsername: dsuser\nPassword: P@ssw0rd\n\nBefore starting, make sure to install the required R packages in your local machine:\ninstall.packages('DSI')\ninstall.packages('DSOpal')\n\ninstall.packages('dsBaseClient', repos=c(getOption('repos'), 'http://cran.datashield.org'), dependencies=TRUE)\n\ninstall.packages(\"metafor\")\ndevtools::install_github(\"timcadman/ds-helper\")"
  }
]